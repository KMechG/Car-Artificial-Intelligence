{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "trafficSign.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP91twpa83nAaBxLLliahpe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KMechG/Car-Artificial-Intelligence/blob/main/trafficSign.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaH_KFYnFPhc",
        "outputId": "68ea610d-f963-422e-8149-786ea65386f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['car45.png', 'car41.png', 'car16.png', 'car39.png', 'car50.png', 'car30.png', 'car55.png', 'car27.png', 'car7.png', 'car31.png', 'car46.png', 'car3.png', 'car23.png', 'car4.png', 'car18.png', 'car11.png', 'car53.png', 'car0.png', 'car33.png', 'car6.png', 'car20.png', 'car28.png', 'car49.png', 'car8.png', 'car36.png', 'car22.png', 'car29.png', 'car2.png', 'car21.png', 'car32.png', 'car14.png', 'car13.png', 'car34.png', 'car37.png', 'car15.png', 'car17.png', 'car1.png', 'car47.png', 'car40.png', 'car35.png', 'car26.png', 'car12.png', 'car5.png', 'car42.png', 'car54.png', 'car19.png', 'car48.png', 'car52.png', 'car38.png', 'car43.png', 'car51.png', 'car25.png', 'car44.png', 'car9.png', 'car24.png', 'car10.png']\n",
            "width, height: 720.0 480.0\n",
            "fps: 30.0\n",
            "frames count: 56.0\n",
            "cv2.CAP_PROP_FRAME_WIDTH : 3\n",
            "cv2.CAP_PROP_FRAME_HEIGHT: 4\n",
            "cv2.CAP_PROP_FPS         : 5\n",
            "cv2.CAP_PROP_FRAME_COUNT : 7\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import time\n",
        "from timeit import default_timer as timer\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "\n",
        "#print(os.listdir('/content/sample_data/input'))\n",
        "\n",
        "#Read Video\n",
        "\n",
        "vcap = cv2.VideoCapture(\"/content/20141025_141223_1097_1247.avi\")\n",
        "\n",
        "# Writer that will be used to write processed frames\n",
        "writer = None\n",
        "\n",
        "# Variables for spatial dimensions of the frames\n",
        "h, w = None, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Processing single image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Proceed Frame\n",
        "if vcap.isOpened(): \n",
        "    width  = vcap.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
        "    height = vcap.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
        "    \n",
        "\n",
        "    print('width, height:', width, height)\n",
        "    \n",
        "    fps = vcap.get(cv2.CAP_PROP_FPS)\n",
        "    \n",
        "    \n",
        "    print('fps:', fps)  # float `fps`\n",
        "    \n",
        "    frame_count = vcap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
        "    \n",
        "    \n",
        "    print('frames count:', frame_count)  # float `frame_count`\n",
        "    print('cv2.CAP_PROP_FRAME_WIDTH :', cv2.CAP_PROP_FRAME_WIDTH)   # 3\n",
        "    print('cv2.CAP_PROP_FRAME_HEIGHT:', cv2.CAP_PROP_FRAME_HEIGHT)  # 4\n",
        "    print('cv2.CAP_PROP_FPS         :', cv2.CAP_PROP_FPS)           # 5\n",
        "    print('cv2.CAP_PROP_FRAME_COUNT :', cv2.CAP_PROP_FRAME_COUNT)   # 7\n"
      ],
      "metadata": {
        "id": "3mZi2Cru55g3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save framme as image\n",
        "\n",
        "i=0\n",
        "while(vcap.isOpened()):\n",
        "    ret, frame = vcap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite('/content/sample_data/input/car'+str(i)+'.png',frame)\n",
        "    i+=1\n",
        " \n",
        "vcap.release()\n",
        "cv2.destroyAllWindows()\n",
        "#image_BGR = cv2.imread('/content/sample_data/input/car54.png')\n",
        "#print(image_BGR)"
      ],
      "metadata": {
        "id": "yNMIMD_o6IBI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}